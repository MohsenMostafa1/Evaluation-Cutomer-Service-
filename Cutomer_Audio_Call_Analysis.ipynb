{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Model provides a complete workflow for converting audio to text, analyzing the sentiment of the text, and classifying the overall sentiment of a conversation."
      ],
      "metadata": {
        "id": "iX-hHkssIIQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necassary libraries\n"
      ],
      "metadata": {
        "id": "UXGa9-rOr2Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install vaderSentiment\n",
        "!pip install pydub\n",
        "!pip install ffmpeg\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"\\nDone\")"
      ],
      "metadata": {
        "id": "6IdRgk7AIKJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Convert audio into text.\n",
        "Process:\n",
        "\n",
        "\n",
        "  torch: A library for tensor computation and deep learning.\n",
        "\n",
        "  gdown: Used to download files from Google Drive.\n",
        "\n",
        "  transformers: Contains classes for handling pre-trained models from the Hugging Face library, specifically for BERT in this case.\n",
        "\n",
        "  speech_recognition: A library for converting speech into text.\n",
        "\n",
        "  pydub: A library for audio manipulation.\n",
        "\n",
        "\n",
        "  Use pydub to load the audio file and convert it to a mono channel with a 16kHz sample rate.\n",
        "\n",
        "  Export the audio as a WAV file.\n",
        "  \n",
        "  Use speech_recognition to transcribe the audio to text using Google’s speech recognition service."
      ],
      "metadata": {
        "id": "_bmiTyc3IU4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gdown\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def convert_audio_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "    audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "    audio.export(\"temp.wav\", format=\"wav\")\n",
        "\n",
        "    with sr.AudioFile(\"temp.wav\") as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        conversation_text = recognizer.recognize_google(audio_data)\n",
        "        return conversation_text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Speech Recognition could not understand audio\")\n",
        "        return None\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Mn3jlZDcIVOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Prepare the text for sentiment analysis.\n",
        "\n",
        "Process: Split the text into sentences by periods. This allows each sentence to be analyzed individually."
      ],
      "metadata": {
        "id": "YkBpzBuBO9m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    sentences = text.split(\".\")\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "bx4BvuUNO-AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Analyze the sentiment of each sentence.\n",
        "Process:\n",
        "\n",
        "  Use a pre-trained BERT model for sentiment analysis from the nlptown library.\n",
        "\n",
        "  Tokenize each sentence and pass it through the model.\n",
        "\n",
        "  Calculate the sentiment score based on the model’s output.\n",
        "\n",
        "  Count the number of positive, negative, and neutral sentences based on the score."
      ],
      "metadata": {
        "id": "5SS_sy2mPSi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(sentences):\n",
        "    model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "    positive, negative, neutral = 0, 0, 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        outputs = model(**inputs)\n",
        "        probs = softmax(outputs.logits, dim=-1)\n",
        "        sentiment_score = torch.argmax(probs)\n",
        "\n",
        "        if sentiment_score in [4, 3]:\n",
        "            positive += 1\n",
        "        elif sentiment_score in [0, 1]:\n",
        "            negative += 1\n",
        "        else:\n",
        "            neutral += 1\n",
        "\n",
        "    return positive, negative, neutral\n"
      ],
      "metadata": {
        "id": "MQZLbWZZPfWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Calculate the percentage of positive, negative, and neutral sentences.\n",
        "\n",
        "Process: Compute the percentage of each sentiment category relative to the total number of sentences."
      ],
      "metadata": {
        "id": "YQK7YszkPkmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_percentage(positive, negative, neutral):\n",
        "    total = positive + negative + neutral\n",
        "    if total == 0:\n",
        "        return 0, 0, 0\n",
        "    positive_percentage = (positive / total) * 100\n",
        "    negative_percentage = (negative / total) * 100\n",
        "    neutral_percentage = (neutral / total) * 100\n",
        "    return positive_percentage, negative_percentage, neutral_percentage\n"
      ],
      "metadata": {
        "id": "MQZVgAnTPpkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Run the entire pipeline from audio to sentiment classification.\n",
        "Process:\n",
        "\n",
        "  Convert the audio file to text.\n",
        "\n",
        "  Preprocess the text into sentences.\n",
        "\n",
        "  Analyze the sentiment of each sentence.\n",
        "\n",
        "  Calculate the percentage of each sentiment.\n",
        "  \n",
        "  Print the results and classify the overall sentiment of the conversation."
      ],
      "metadata": {
        "id": "bFPYvjYwPsD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(audio_file):\n",
        "    print(\"Converting audio to text...\")\n",
        "    conversation_text = convert_audio_to_text(audio_file)\n",
        "    if not conversation_text:\n",
        "        print(\"No text extracted from audio.\")\n",
        "        return\n",
        "\n",
        "    print(\"Preprocessing text...\")\n",
        "    sentences = preprocess_text(conversation_text)\n",
        "\n",
        "    print(\"Analyzing sentiment with BERT...\")\n",
        "    positive, negative, neutral = analyze_sentiment(sentences)\n",
        "\n",
        "    print(\"Calculating percentages...\")\n",
        "    positive_percentage, negative_percentage, neutral_percentage = calculate_percentage(positive, negative, neutral)\n",
        "\n",
        "    print(f\"Positive Sentiment: {positive_percentage:.2f}%\")\n",
        "    print(f\"Negative Sentiment: {negative_percentage:.2f}%\")\n",
        "    print(f\"Neutral Sentiment: {neutral_percentage:.2f}%\")\n",
        "\n",
        "    if positive_percentage > negative_percentage and positive_percentage > neutral_percentage:\n",
        "        print(\"The call is classified as Positive in terms of customer satisfaction.\")\n",
        "    elif negative_percentage > positive_percentage and negative_percentage > neutral_percentage:\n",
        "        print(\"The call is classified as Negative in terms of customer satisfaction.\")\n",
        "    else:\n",
        "        print(\"The call is classified as Neutral in terms of customer satisfaction.\")\n"
      ],
      "metadata": {
        "id": "JsxEONRUP1Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Download an audio file and process it.\n",
        "Process:\n",
        "\n",
        "  Use gdown to download the audio file from Google Drive.\n",
        "  \n",
        "  Call the main function to process the downloaded audio file."
      ],
      "metadata": {
        "id": "uObvfzCYP4ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    url = \"https://drive.google.com/uc?id=191pj9uBliYFx7XVh6e6iGYPLt5e_Asc3\"\n",
        "    output = \"AudioCall.mp3\"\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    audio_file_path = \"AudioCall.mp3\"\n",
        "    main(audio_file_path)\n"
      ],
      "metadata": {
        "id": "1VexhqurP_4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}