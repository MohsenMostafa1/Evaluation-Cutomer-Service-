# -*- coding: utf-8 -*-
"""Sentiment Analysis for Customer AudioCall Multiple Files.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZvEL_TXDwCl58UohHGOd9bbICezRQvot
"""

!pip install SpeechRecognition
!pip install vaderSentiment
!pip install pydub
!pip install ffmpeg

from IPython.display import clear_output
clear_output()
print("\nDone")

import torch
import gdown
from transformers import BertTokenizer, BertForSequenceClassification
from torch.nn.functional import softmax
import speech_recognition as sr
from pydub import AudioSegment

# Step 1: Convert Audio to Text (same as before)
def convert_audio_to_text(audio_file):
    recognizer = sr.Recognizer()
    audio = AudioSegment.from_file(audio_file)
    audio = audio.set_channels(1).set_frame_rate(16000)
    audio.export("temp.wav", format="wav")

    with sr.AudioFile("temp.wav") as source:
        audio_data = recognizer.record(source)

    try:
        conversation_text = recognizer.recognize_google(audio_data)
        return conversation_text
    except sr.UnknownValueError:
        print("Google Speech Recognition could not understand audio")
        return None
    except sr.RequestError as e:
        print(f"Could not request results from Google Speech Recognition service; {e}")
        return None

# Step 2: Text Preprocessing (same as before)
def preprocess_text(text):
    sentences = text.split(".")
    return sentences

# Step 3: Deep Learning Sentiment Analysis
def analyze_sentiment(sentences):
    model_name = "nlptown/bert-base-multilingual-uncased-sentiment"  # Pre-trained BERT model for sentiment analysis
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertForSequenceClassification.from_pretrained(model_name)

    positive, negative, neutral = 0, 0, 0

    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors="pt", truncation=True, padding=True)
        outputs = model(**inputs)
        probs = softmax(outputs.logits, dim=-1)
        sentiment_score = torch.argmax(probs)

        # Mapping sentiment_score to positive, negative, neutral
        if sentiment_score in [4, 3]:  # 4 and 3 represent strong and weak positive respectively
            positive += 1
        elif sentiment_score in [0, 1]:  # 0 and 1 represent strong and weak negative respectively
            negative += 1
        else:  # 2 represents neutral
            neutral += 1

    return positive, negative, neutral

# Step 4: Percentage Calculation (same as before)
def calculate_percentage(positive, negative, neutral):
    total = positive + negative + neutral
    if total == 0:
        return 0, 0, 0
    positive_percentage = (positive / total) * 100
    negative_percentage = (negative / total) * 100
    neutral_percentage = (neutral / total) * 100
    return positive_percentage, negative_percentage, neutral_percentage

# Main function to run all steps for a single audio file
def process_audio_file(audio_file):
    print(f"Processing file: {audio_file}")

    conversation_text = convert_audio_to_text(audio_file)
    if not conversation_text:
        print(f"No text extracted from {audio_file}.")
        return

    sentences = preprocess_text(conversation_text)

    positive, negative, neutral = analyze_sentiment(sentences)

    positive_percentage, negative_percentage, neutral_percentage = calculate_percentage(positive, negative, neutral)

    print(f"File: {audio_file}")
    print(f"Positive Sentiment: {positive_percentage:.2f}%")
    print(f"Negative Sentiment: {negative_percentage:.2f}%")
    print(f"Neutral Sentiment: {neutral_percentage:.2f}%")

    if positive_percentage > negative_percentage and positive_percentage > neutral_percentage:
        print("The call is classified as Positive in terms of customer satisfaction.")
    elif negative_percentage > positive_percentage and negative_percentage > neutral_percentage:
        print("The call is classified as Negative in terms of customer satisfaction.")
    else:
        print("The call is classified as Neutral in terms of customer satisfaction.")
    print("\n")

# Main function to download multiple files and process them
if __name__ == "__main__":
    urls = [
        "https://drive.google.com/uc?id=1lnyyBrJuZ16haL9In-rAoiyeNxQJoFww",
        "https://drive.google.com/uc?id=1siHFN6GdFIFs9oaqou3sZ__UFtaCq7i7",
        "https://drive.google.com/uc?id=191pj9uBliYFx7XVh6e6iGYPLt5e_Asc3",
        "https://drive.google.com/uc?id=1TFrFWZY0Z7IF3cUMAz3BcSHNLYZjwARQ",
        "https://drive.google.com/uc?id=1Q7L8M2z_YFFhyX4FaP2qYQs_21YjDFVB",
        "https://drive.google.com/uc?id=1olCg0iJ_-eylIKJdsxCz3fHhq79JANgE"
    ]

    for i, url in enumerate(urls):
        output = f"AudioCall_{i+1}.mp3"
        gdown.download(url, output, quiet=False)

        # Process each downloaded audio file
        process_audio_file(output)

