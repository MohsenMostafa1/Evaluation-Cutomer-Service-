{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZnRYD-537e4",
        "outputId": "dfc9cb8d-8d6a-479e-cba6-5d71c39bbdae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n",
            "Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.4\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.7.4)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install SpeechRecognition\n",
        "!pip install vaderSentiment\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gdown\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Step 1: Convert Audio to Text (same as before)\n",
        "def convert_audio_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "    audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "    audio.export(\"temp.wav\", format=\"wav\")\n",
        "\n",
        "    with sr.AudioFile(\"temp.wav\") as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        conversation_text = recognizer.recognize_google(audio_data)\n",
        "        return conversation_text\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Speech Recognition could not understand audio\")\n",
        "        return None\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "        return None\n",
        "\n",
        "# Step 2: Text Preprocessing (same as before)\n",
        "def preprocess_text(text):\n",
        "    sentences = text.split(\".\")\n",
        "    return sentences\n",
        "\n",
        "# Step 3: Deep Learning Sentiment Analysis\n",
        "def analyze_sentiment(sentences):\n",
        "    model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"  # Pre-trained BERT model for sentiment analysis\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "    positive, negative, neutral = 0, 0, 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        outputs = model(**inputs)\n",
        "        probs = softmax(outputs.logits, dim=-1)\n",
        "        sentiment_score = torch.argmax(probs)\n",
        "\n",
        "        # Mapping sentiment_score to positive, negative, neutral\n",
        "        if sentiment_score in [4, 3]:  # 4 and 3 represent strong and weak positive respectively\n",
        "            positive += 1\n",
        "        elif sentiment_score in [0, 1]:  # 0 and 1 represent strong and weak negative respectively\n",
        "            negative += 1\n",
        "        else:  # 2 represents neutral\n",
        "            neutral += 1\n",
        "\n",
        "    return positive, negative, neutral\n",
        "\n",
        "# Step 4: Percentage Calculation (same as before)\n",
        "def calculate_percentage(positive, negative, neutral):\n",
        "    total = positive + negative + neutral\n",
        "    if total == 0:\n",
        "        return 0, 0, 0\n",
        "    positive_percentage = (positive / total) * 100\n",
        "    negative_percentage = (negative / total) * 100\n",
        "    neutral_percentage = (neutral / total) * 100\n",
        "    return positive_percentage, negative_percentage, neutral_percentage\n",
        "\n",
        "# Main function to run all steps\n",
        "def main(audio_file):\n",
        "    print(\"Converting audio to text...\")\n",
        "    conversation_text = convert_audio_to_text(audio_file)\n",
        "    if not conversation_text:\n",
        "        print(\"No text extracted from audio.\")\n",
        "        return\n",
        "\n",
        "    print(\"Preprocessing text...\")\n",
        "    sentences = preprocess_text(conversation_text)\n",
        "\n",
        "    print(\"Analyzing sentiment with BERT...\")\n",
        "    positive, negative, neutral = analyze_sentiment(sentences)\n",
        "\n",
        "    print(\"Calculating percentages...\")\n",
        "    positive_percentage, negative_percentage, neutral_percentage = calculate_percentage(positive, negative, neutral)\n",
        "\n",
        "    print(f\"Positive Sentiment: {positive_percentage:.2f}%\")\n",
        "    print(f\"Negative Sentiment: {negative_percentage:.2f}%\")\n",
        "    print(f\"Neutral Sentiment: {neutral_percentage:.2f}%\")\n",
        "\n",
        "     # Assessing customer satisfaction\n",
        "    if positive_percentage > negative_percentage and positive_percentage > neutral_percentage:\n",
        "        print(\"The call is classified as Positive in terms of customer satisfaction.\")\n",
        "    elif negative_percentage > positive_percentage and negative_percentage > neutral_percentage:\n",
        "        print(\"The call is classified as Negative in terms of customer satisfaction.\")\n",
        "    else:\n",
        "        print(\"The call is classified as Neutral in terms of customer satisfaction.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Download file from Google Drive (update the URL with your file's ID)\n",
        "    url = \"https://drive.google.com/uc?id=1siHFN6GdFIFs9oaqou3sZ__UFtaCq7i7\"\n",
        "    output = \"AudioCall.mp3\"\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Use the downloaded file\n",
        "    audio_file_path = \"AudioCall.mp3\"\n",
        "    main(audio_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nouImo_f4Mfj",
        "outputId": "ec149e8d-3793-469f-e0e3-29254a6dfa2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1siHFN6GdFIFs9oaqou3sZ__UFtaCq7i7\n",
            "To: /content/AudioCall.mp3\n",
            "100%|██████████| 3.75M/3.75M [00:00<00:00, 222MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting audio to text...\n",
            "Preprocessing text...\n",
            "Analyzing sentiment with BERT...\n",
            "Calculating percentages...\n",
            "Positive Sentiment: 100.00%\n",
            "Negative Sentiment: 0.00%\n",
            "Neutral Sentiment: 0.00%\n",
            "The call is classified as Positive in terms of customer satisfaction.\n"
          ]
        }
      ]
    }
  ]
}